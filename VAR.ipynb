{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "#import tensorflow as tf\n",
    "#tf.random.set_seed(2)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.layers import LSTM\n",
    "#from keras.layers import Dropout\n",
    "#from keras.layers import Flatten\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(sqs, lag):\n",
    "    cols, names = list(), list()\n",
    "    F = sqs.drop(columns={\"date\"}, axis=1)\n",
    "    columns = F.columns\n",
    "    n_var = F.shape[1]\n",
    "    for i in range(lag, 0, -1):\n",
    "        cols.append(F.shift(i))\n",
    "        names +=([(columns[j]+'_t-%d' % i) for j in range(n_var)])\n",
    "    cols.append(F)\n",
    "    names += F.columns.tolist()\n",
    "    reframed = concat(cols, axis=1)\n",
    "    reframed.columns = names\n",
    "    reframed = reframed.drop(reframed.columns[[-1,-2]], axis=1)\n",
    "    return reframed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the lstm model\n",
    "def fit_lstm(train,time_step, batch_size, neurons):\n",
    "    mean_loss = 0\n",
    "    X, y = train[:, 3*(4-time_step):-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], time_step, int(X.shape[1]/time_step))\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), \n",
    "                   stateful=True, return_sequences = True))\n",
    "    model.add(LSTM(units = neurons, return_sequences = False))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(30):\n",
    "        history = model.fit(X, y, epochs=1000, batch_size=batch_size, verbose=0, \n",
    "                        shuffle=False, validation_split = 0.2)\n",
    "        model.reset_states()\n",
    "        mean_loss += min(history.history['val_loss'])\n",
    "    return mean_loss/30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varData(M):\n",
    "    data = M\n",
    "    data = data.drop(columns = 'Inventor')\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data = data[(data['date'] > '1997-01-01') & (data['date'] < '2019-01-01')]\n",
    "    data.set_index('date', inplace = True)\n",
    "    data = data.rename(columns={\"counts\": \"patent\", \"Citation\": \"citing_cnt\"})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def patentCitingPlot(data):\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.plot(data['patent'],\"x-\",label=\"patent\")\n",
    "    plt.plot(data['citing_cnt'],label=\"citation\")\n",
    "    plt.legend(bbox_to_anchor=(1.0, 1), loc=1, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# causality test\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "maxlag=12\n",
    "test = 'ssr_chi2test'\n",
    "def grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    \n",
    "    \"\"\"Check Granger Causality of all possible combinations of the Time series.\n",
    "    The rows are the response variable, columns are predictors. The values in the table \n",
    "    are the P-Values. P-Values lesser than the significance level (0.05), implies \n",
    "    the Null Hypothesis that the coefficients of the corresponding past values is \n",
    "    zero, that is, the X does not cause Y can be rejected.\n",
    "\n",
    "    data      : pandas dataframe containing the time series variables\n",
    "    variables : list containing names of the time series variables.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stationary test\n",
    "def adfuller_test(series, signif=0.05, name='', verbose=False):\n",
    "    \"\"\"Perform ADFuller to test for Stationarity of given series and print report\"\"\"\n",
    "    r = adfuller(series, autolag='AIC')\n",
    "    output = {'test_statistic':round(r[0], 4), 'pvalue':round(r[1], 4), 'n_lags':round(r[2], 4), 'n_obs':r[3]}\n",
    "    p_value = output['pvalue'] \n",
    "    def adjust(val, length= 6): return str(val).ljust(length)\n",
    "\n",
    "    # Print Summary\n",
    "    print(f'    Augmented Dickey-Fuller Test on \"{name}\"', \"\\n   \", '-'*47)\n",
    "    print(f' Null Hypothesis: Data has unit root. Non-Stationary.')\n",
    "    print(f' Significance Level    = {signif}')\n",
    "    print(f' Test Statistic        = {output[\"test_statistic\"]}')\n",
    "    print(f' No. Lags Chosen       = {output[\"n_lags\"]}')\n",
    "\n",
    "    for key,val in r[4].items():\n",
    "        print(f' Critical value {adjust(key)} = {round(val, 3)}')\n",
    "\n",
    "    if p_value <= signif:\n",
    "        print(f\" => P-Value = {p_value}. Rejecting Null Hypothesis.\")\n",
    "        print(f\" => Series is Stationary.\")\n",
    "    else:\n",
    "        print(f\" => P-Value = {p_value}. Weak evidence to reject the Null Hypothesis.\")\n",
    "        print(f\" => Series is Non-Stationary.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitVar(input):\n",
    "    from statsmodels.tsa.api import VAR\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "    from statsmodels.tools.eval_measures import rmse, aic\n",
    "\n",
    "    Data = varData(input)\n",
    "\n",
    "    train = Data[(Data.index < '2016-01-01') ]\n",
    "    test = Data[(Data.index >= '2016-01-01') ]\n",
    "\n",
    "    # differenced once\n",
    "    differenced = train.diff().dropna()\n",
    "    #differenced = differenced.diff().dropna()\n",
    "\n",
    "    model = VAR(differenced)\n",
    "\n",
    "    # find the order\n",
    "    order = {}\n",
    "    for i in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "        result = model.fit(i)\n",
    "        order[i] = result.aic\n",
    "\n",
    "\n",
    "    o = min(order,key = order.get)\n",
    "\n",
    "    model_fitted = model.fit(o)\n",
    "    model_fitted.summary()\n",
    "\n",
    "    forecast_input = differenced.values[-o:]\n",
    "\n",
    "    nobs = len(test)\n",
    "\n",
    "    fc = model_fitted.forecast(y=forecast_input, steps=nobs)\n",
    "    forecast = pd.DataFrame(fc, index=Data.index[-nobs:], columns=Data.columns + '_1d')\n",
    "\n",
    "    forecast\n",
    "\n",
    "    def invert_transformation(df_train, df_forecast, second_diff=False):\n",
    "        \"\"\"Revert back the differencing to get the forecast to original scale.\"\"\"\n",
    "        df_fc = df_forecast.copy()\n",
    "        columns = df_train.columns\n",
    "        for col in columns:        \n",
    "            # Roll back 2nd Diff\n",
    "            if second_diff:\n",
    "                df_fc[str(col)+'_1d'] = (df_train[col].iloc[-1]-df_train[col].iloc[-2]) + df_fc[str(col)+'_2d'].cumsum()\n",
    "            # Roll back 1st Diff\n",
    "            df_fc[str(col)+'_forecast'] = df_train[col].iloc[-1] + df_fc[str(col)+'_1d'].cumsum()\n",
    "        return df_fc\n",
    "\n",
    "    results = invert_transformation(train, forecast, second_diff=False) \n",
    "\n",
    "    results.loc[:,['patent_forecast', 'citing_cnt_forecast']]\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=int(len(Data.columns)/2), ncols=2, dpi=150, figsize=(10,4))\n",
    "    for i, (col,ax) in enumerate(zip(Data.columns, axes.flatten())):\n",
    "        results[col+'_forecast'].plot(legend=True, ax=ax).autoscale(axis='x',tight=True)\n",
    "        test[col][-nobs:].plot(legend=True, ax=ax);\n",
    "        ax.set_title(col + \": Forecast vs Actuals\")\n",
    "        ax.xaxis.set_ticks_position('none')\n",
    "        ax.yaxis.set_ticks_position('none')\n",
    "        ax.spines[\"top\"].set_alpha(0)\n",
    "        ax.tick_params(labelsize=6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return results.loc[:,['patent_forecast']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterlyResult = fitVar(Q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
